Question 2

Review of Phalanx: Withstanding multimillion node botnets

This article presents Phalanx, a novel Denial of Service prevention scheme which can address botnets composed of a very large number of attacker nodes. This number is only limited by the number of nodes belonging to the "good" swarm.

The main concept of the proposed algorithm is the mailbox. These blocks receive packets which are intended to a different destination and then it is up to the destination to either get this packets or to simple ignore them. This way they serve as proxies receiving and temporarily buffering traffic on behalf of end-hosts.

Which flows are directed to which mailboxes is built by iterating a cryptographic hash function over a shared secret by both endpoints of the connection.

But before the server knows to which mailboxes issue a get command it a first packet must be delivered by the server. This is performed by issuing periodic special packets representing connection establishment. As this type of packets is a scarce resource, attacker would attack it first rendering the rest of the algorithm useless. To avoid this problem, clients are required to either present an authentication token or to present a cryptographic puzzle solution.

One side issue this algorithm causes in the network is to divide nodes in either protected nodes or nodes with mailboxes. This happens because all packets received by a protected packets must be explicitly requested by the destination (being the rest of the packets discarded). By the contrary, mailbox nodes must be able to receive packets originating from anywhere. Because of this, a protected node could never be a mailbox node simultaneously.

Phalanx effectively avoids abusive resource (memory, cpu and link capacity) of nodes providing read/write services by "distributing" these resources by a swarm of mailbox nodes. One of the main advantages of these algorithm over similar solutions is that it is possible to start implementing the algorithm in a single ISP ant not the entire network. Despite not the optimal solution, if a large ISP started to offer this solution, it could benefit its costumers.

For testing the solution, the article implements a prototype in planetlab and in a simulator using measured internet topologies.

There are two main weaknesses associated with the proposed solution. The first one is the requirement that the filtering ring be extremely fast even on high speed links. Although using bloom filters to speed up the process, there is always a processing/memory overhead in implementing these filters. Many ISPs may simple not be interested on occurring that overhead. The other problem relies on having a large enough number of "good" clients accepting to serve as mailboxes. There has to be some advantages to these users to accept sharing their resources to solve problems of third party endpoints.
